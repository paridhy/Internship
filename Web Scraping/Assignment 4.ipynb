{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "521fb05c-743c-47ed-98ab-98dfd03187c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "import re\n",
    "\n",
    "#importing requires exceptions which needs to handled\n",
    "from selenium.common.exceptions import NoSuchElementException,StaleElementReferenceException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffb5252",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b2518b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#automating chrome browser\n",
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f53b60c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos=[]\n",
    "video=[]\n",
    "uploader=[]\n",
    "date_=[]\n",
    "views=[]\n",
    "\n",
    "#giving delay until element is located\n",
    "WebDriverWait(driver, 4).until(EC.presence_of_element_located((By.XPATH,\"/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table[2]/thead/tr/th[1]\")))\n",
    "\n",
    "#string from 1 to 30 \n",
    "pos= [str(i) for i in range(1, 31)]\n",
    "    \n",
    "#scraping video name\n",
    "\n",
    "try:\n",
    "    for name in driver.find_elements(By.XPATH,\"//div[@id='mw-content-text']/div/table[2]/tbody/tr/td[1]\"):\n",
    "        video.append(name.text)\n",
    "except Exception:\n",
    "    video.append('-')\n",
    "    \n",
    "#scraping artist name\n",
    "\n",
    "try:\n",
    "    for art in driver.find_elements(By.XPATH,\"//div[@id='mw-content-text']/div/table[2]/tbody/tr/td[2]\"):\n",
    "        uploader.append(art.text)\n",
    "except Exception:\n",
    "    uploader.append('-')\n",
    "    \n",
    "#scraping date\n",
    "\n",
    "try:\n",
    "    for d in driver.find_elements(By.XPATH,\"//div[@id='mw-content-text']/div/table[2]/tbody/tr/td[4]\"):\n",
    "        date_.append(d.text)\n",
    "except Exception:\n",
    "    date_.append('-')\n",
    "    \n",
    "#scraping views\n",
    "\n",
    "try:\n",
    "    for v in driver.find_elements(By.XPATH,\"//div[@id='mw-content-text']/div/table[2]/tbody/tr/td[3]\"):\n",
    "        views.append(v.text)\n",
    "except Exception:\n",
    "    views.append('-')  \n",
    "    \n",
    "driver.quit()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "58c66357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Video Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views (billions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Axel F\"[38]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[41]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\"Baby Shark Dance\"[6]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>14.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>\"Bath Song\"[18]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\"Counting Stars\"[40]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>\"Dame Tu Cosita\"[37]</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>\"Dark Horse\"[49]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>\"Despacito\"[9]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>\"Faded\"[52]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>\"Gangnam Style\"[31]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>5.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>\"Girls Like You\"[53]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[47]</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[17]</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[43]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>\"Lean On\"[54]</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>\"Learning Colors ‚Äì Colorful Eggs on a Farm\"[30]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>5.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>\"Let Her Go\"[51]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>\"Masha and the Bear ‚Äì Recipe for Disaster\"[36]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>\"Perfect\"[50]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>\"Phonics Song with Two Words\"[28]</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>\"Roar\"[42]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>\"See You Again\"[22]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>6.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>\"Shape of You\"[19]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>\"Shree Hanuman Chalisa\"[48]</td>\n",
       "      <td>T-Series Bhakti Sagar</td>\n",
       "      <td>May 10, 2011</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>\"Sorry\"[45]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>\"Sugar\"[39]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>\"Thinking Out Loud\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>\"Uptown Funk\"[29]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>5.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[44]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>\"Wheels on the Bus\"[27]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>5.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                       Video Name  \\\n",
       "0     1                                     \"Axel F\"[38]   \n",
       "1     2                        \"Baa Baa Black Sheep\"[41]   \n",
       "2     3                            \"Baby Shark Dance\"[6]   \n",
       "3     4                                  \"Bath Song\"[18]   \n",
       "4     5                             \"Counting Stars\"[40]   \n",
       "5     6                             \"Dame Tu Cosita\"[37]   \n",
       "6     7                                 \"Dark Horse\"[49]   \n",
       "7     8                                   \"Despacito\"[9]   \n",
       "8     9                                      \"Faded\"[52]   \n",
       "9    10                              \"Gangnam Style\"[31]   \n",
       "10   11                             \"Girls Like You\"[53]   \n",
       "11   12          \"Humpty the train on a fruits ride\"[47]   \n",
       "12   13                       \"Johny Johny Yes Papa\"[17]   \n",
       "13   14                             \"Lakdi Ki Kathi\"[43]   \n",
       "14   15                                    \"Lean On\"[54]   \n",
       "15   16  \"Learning Colors ‚Äì Colorful Eggs on a Farm\"[30]   \n",
       "16   17                                 \"Let Her Go\"[51]   \n",
       "17   18   \"Masha and the Bear ‚Äì Recipe for Disaster\"[36]   \n",
       "18   19                                    \"Perfect\"[50]   \n",
       "19   20                \"Phonics Song with Two Words\"[28]   \n",
       "20   21                                       \"Roar\"[42]   \n",
       "21   22                              \"See You Again\"[22]   \n",
       "22   23                               \"Shape of You\"[19]   \n",
       "23   24                      \"Shree Hanuman Chalisa\"[48]   \n",
       "24   25                                      \"Sorry\"[45]   \n",
       "25   26                                      \"Sugar\"[39]   \n",
       "26   27                          \"Thinking Out Loud\"[46]   \n",
       "27   28                                \"Uptown Funk\"[29]   \n",
       "28   29           \"Waka Waka (This Time for Africa)\"[44]   \n",
       "29   30                          \"Wheels on the Bus\"[27]   \n",
       "\n",
       "                                               Artist        Upload Date  \\\n",
       "0                                          Crazy Frog      June 16, 2009   \n",
       "1                          Cocomelon - Nursery Rhymes      June 25, 2018   \n",
       "2         Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "3                          Cocomelon - Nursery Rhymes        May 2, 2018   \n",
       "4                                         OneRepublic       May 31, 2013   \n",
       "5                                       Ultra Records      April 5, 2018   \n",
       "6                                          Katy Perry  February 20, 2014   \n",
       "7                                          Luis Fonsi   January 12, 2017   \n",
       "8                                         Alan Walker   December 3, 2015   \n",
       "9                                                 Psy      July 15, 2012   \n",
       "10                                           Maroon 5       May 31, 2018   \n",
       "11      Kiddiestv Hindi - Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "12  LooLoo Kids - Nursery Rhymes and Children's Songs    October 8, 2016   \n",
       "13                                       Jingle Toons      June 14, 2018   \n",
       "14                               Major Lazer Official     March 22, 2015   \n",
       "15                                        Miroshka TV  February 27, 2018   \n",
       "16                                          Passenger      July 25, 2012   \n",
       "17                                         Get Movies   January 31, 2012   \n",
       "18                                         Ed Sheeran   November 9, 2017   \n",
       "19              ChuChu TV Nursery Rhymes & Kids Songs      March 6, 2014   \n",
       "20                                         Katy Perry  September 5, 2013   \n",
       "21                                        Wiz Khalifa      April 6, 2015   \n",
       "22                                         Ed Sheeran   January 30, 2017   \n",
       "23                              T-Series Bhakti Sagar       May 10, 2011   \n",
       "24                                      Justin Bieber   October 22, 2015   \n",
       "25                                           Maroon 5   January 14, 2015   \n",
       "26                                         Ed Sheeran    October 7, 2014   \n",
       "27                                        Mark Ronson  November 19, 2014   \n",
       "28                                            Shakira       June 4, 2010   \n",
       "29                         Cocomelon - Nursery Rhymes       May 24, 2018   \n",
       "\n",
       "   Views (billions)  \n",
       "0              4.34  \n",
       "1              3.96  \n",
       "2             14.09  \n",
       "3              6.62  \n",
       "4              3.97  \n",
       "5              4.55  \n",
       "6              3.67  \n",
       "7              8.38  \n",
       "8              3.59  \n",
       "9              5.05  \n",
       "10             3.56  \n",
       "11             3.73  \n",
       "12             6.87  \n",
       "13             3.91  \n",
       "14             3.55  \n",
       "15             5.07  \n",
       "16             3.61  \n",
       "17             4.58  \n",
       "18             3.67  \n",
       "19             5.70  \n",
       "20             3.96  \n",
       "21             6.17  \n",
       "22             6.20  \n",
       "23             3.69  \n",
       "24             3.77  \n",
       "25             4.00  \n",
       "26             3.73  \n",
       "27             5.15  \n",
       "28             3.85  \n",
       "29             5.88  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1=pd.DataFrame({'Rank':pos,'Video Name':video,'Artist':uploader,'Upload Date':date_,'Views (billions)':views})\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadbc80a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "559fd83c",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "731b1d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#automating chrome browser\n",
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://www.bcci.tv/\")\n",
    "driver.maximize_window()\n",
    "\n",
    "WebDriverWait(driver, 4).until(EC.presence_of_element_located((By.XPATH,\"/html/body/header/div[3]/div[2]/ul/div[1]/a[2]\")))\n",
    "\n",
    "# Locating the international fixture page through code.\n",
    "fixture_tab=driver.find_element(By.XPATH,'/html/body/header/div[3]/div[2]/ul/div[1]/a[2]')\n",
    "fixture_tab.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cca5a8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty Lists\n",
    "\n",
    "series=[]\n",
    "place=[]\n",
    "date=[]\n",
    "time=[]\n",
    " \n",
    "\n",
    "#scraping the Series Name\n",
    "\n",
    "try:\n",
    "    for name in driver.find_elements(By.XPATH,\"//h5[@class='match-tournament-name ng-binding']\"):\n",
    "        series.append(name.text)\n",
    "except Exception:\n",
    "    series.append('-')\n",
    "    \n",
    "#scraping the Place Name\n",
    "\n",
    "try:\n",
    "    venue= driver.find_elements(By.XPATH,\"//div[@class='match-place ng-scope']\")\n",
    "    for v in venue:\n",
    "        place.append(v.text)\n",
    "except Exception:\n",
    "    place.append('-')\n",
    "        \n",
    "#scraping the Date\n",
    "\n",
    "try:\n",
    "    for date_ in driver.find_elements(By.XPATH,\"//div[@class='match-dates ng-binding']\"):\n",
    "        date.append(date_.text)\n",
    "except Exception:\n",
    "    date.append('-')\n",
    "    \n",
    "#scraping the Time\n",
    "\n",
    "try:\n",
    "    for time_ in driver.find_elements(By.XPATH,\"//div[@class='match-dates ng-binding']\"):\n",
    "        time.append(time_.text)\n",
    "except Exception:\n",
    "    time.append('-')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ff65b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series Name</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>Himachal Pradesh Cricket Association Stadium, ...</td>\n",
       "      <td>7 MARCH, 2024</td>\n",
       "      <td>7 MARCH, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>6 JULY, 2024</td>\n",
       "      <td>6 JULY, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>7 JULY, 2024</td>\n",
       "      <td>7 JULY, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>10 JULY, 2024</td>\n",
       "      <td>10 JULY, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>13 JULY, 2024</td>\n",
       "      <td>13 JULY, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>14 JULY, 2024</td>\n",
       "      <td>14 JULY, 2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Series Name  \\\n",
       "0  ENGLAND TOUR OF INDIA 2023-24   \n",
       "1    INDIA TOUR OF ZIMBABWE 2024   \n",
       "2    INDIA TOUR OF ZIMBABWE 2024   \n",
       "3    INDIA TOUR OF ZIMBABWE 2024   \n",
       "4    INDIA TOUR OF ZIMBABWE 2024   \n",
       "5    INDIA TOUR OF ZIMBABWE 2024   \n",
       "\n",
       "                                               Place           Date  \\\n",
       "0  Himachal Pradesh Cricket Association Stadium, ...  7 MARCH, 2024   \n",
       "1                         Harare Sports Club, Harare   6 JULY, 2024   \n",
       "2                         Harare Sports Club, Harare   7 JULY, 2024   \n",
       "3                         Harare Sports Club, Harare  10 JULY, 2024   \n",
       "4                         Harare Sports Club, Harare  13 JULY, 2024   \n",
       "5                         Harare Sports Club, Harare  14 JULY, 2024   \n",
       "\n",
       "            Time  \n",
       "0  7 MARCH, 2024  \n",
       "1   6 JULY, 2024  \n",
       "2   7 JULY, 2024  \n",
       "3  10 JULY, 2024  \n",
       "4  13 JULY, 2024  \n",
       "5  14 JULY, 2024  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2=pd.DataFrame({'Series Name':series,'Place':place,'Date':date,'Time':time})\n",
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c715be",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ceec312",
   "metadata": {},
   "outputs": [],
   "source": [
    "#automating chrome browser\n",
    "driver=webdriver.Chrome()\n",
    "driver.get(\"http://statisticstimes.com/\")\n",
    "driver.maximize_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1570b48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "economy_tab=driver.find_element(By.XPATH,\"/html/body/div[2]/div[1]/div[2]/div[2]/button\")\n",
    "economy_tab.click()\n",
    "sleep(2)\n",
    "india_tab=driver.find_element(By.XPATH,\"(//div[@class='dropdown-content'])[2]/a[3]\")\n",
    "india_tab.click()\n",
    "sleep(2)\n",
    "state_tab=driver.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\")\n",
    "state_tab.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a31bb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank=[]\n",
    "state=[]\n",
    "gsdp_1=[]\n",
    "gsdp_2=[]\n",
    "share=[]\n",
    "gdp=[]\n",
    "count=34\n",
    "\n",
    "#giving delay until element is located\n",
    "WebDriverWait(driver, 4).until(EC.presence_of_element_located((By.XPATH,\"/html/body/div[3]/div[2]/div[5]/div[1]/div/table/tbody/tr[1]/td[1]\")))\n",
    "\n",
    "#scraping rank\n",
    "\n",
    "try:\n",
    "    for a in driver.find_elements(By.XPATH,\"//td[@class='data1']\"):\n",
    "        #so that only 33 items are appended of gsdp table\n",
    "        if len(rank)>=count:\n",
    "            break\n",
    "        else:    \n",
    "            rank.append(a.text)\n",
    "except Exception:\n",
    "    date.append('-')\n",
    "    \n",
    "#scraping state\n",
    "\n",
    "try:\n",
    "    for b in driver.find_elements(By.XPATH,\"//td[@class='name']\"):\n",
    "        if len(state)>=count:\n",
    "            break\n",
    "        else:    \n",
    "            state.append(b.text)\n",
    "except Exception:\n",
    "    state.append('-')\n",
    "    \n",
    "    \n",
    "#scraping gsdp 22-23\n",
    "\n",
    "try:\n",
    "    for c in driver.find_elements(By.XPATH,\"//td[@class='data'][1]\"):\n",
    "        if len(gsdp_1)>=count:\n",
    "            break\n",
    "        else:    \n",
    "            gsdp_1.append(c.text)\n",
    "except Exception:\n",
    "    gsdp_1.append('-')\n",
    "    \n",
    "#scraping gsdp 21-22\n",
    "\n",
    "try:\n",
    "    for d in driver.find_elements(By.XPATH,\"//td[@class='data'][5]\"):\n",
    "        if len(gsdp_2)>=count:\n",
    "            break\n",
    "        else:    \n",
    "            gsdp_2.append(d.text)\n",
    "except Exception:\n",
    "    gsdp_2.append('-')    \n",
    "    \n",
    "    \n",
    "#scraping share 21-22\n",
    "\n",
    "try:\n",
    "    for e in driver.find_elements(By.XPATH,\"//td[@class='data'][2]\"):\n",
    "        if len(share)>=count:\n",
    "            break\n",
    "        else:    \n",
    "            share.append(e.text)\n",
    "except Exception:\n",
    "    share.append('-')\n",
    "    \n",
    "#scraping gdp($ billion)\n",
    "\n",
    "try:\n",
    "    for f in driver.find_elements(By.XPATH,\"//td[@class='data'][3]\"):\n",
    "        if len(gdp)>=count:\n",
    "            break\n",
    "        else:    \n",
    "            gdp.append(f.text)\n",
    "except Exception:\n",
    "    gdp.append('-')    \n",
    "    \n",
    "\n",
    "driver.quit()    \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10e21257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>Share 22-21</th>\n",
       "      <th>GSDP 22-23</th>\n",
       "      <th>GSDP 21-22</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>13.24%</td>\n",
       "      <td>-</td>\n",
       "      <td>2,027,971</td>\n",
       "      <td>417.163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>8.82%</td>\n",
       "      <td>2,364,514</td>\n",
       "      <td>1,343,287</td>\n",
       "      <td>278.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>8.41%</td>\n",
       "      <td>2,257,575</td>\n",
       "      <td>1,204,660</td>\n",
       "      <td>265.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>8.36%</td>\n",
       "      <td>2,241,368</td>\n",
       "      <td>1,229,713</td>\n",
       "      <td>263.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>8.25%</td>\n",
       "      <td>-</td>\n",
       "      <td>1,372,204</td>\n",
       "      <td>259.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>5.81%</td>\n",
       "      <td>1,554,992</td>\n",
       "      <td>787,758</td>\n",
       "      <td>183.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>5.19%</td>\n",
       "      <td>1,413,620</td>\n",
       "      <td>738,922</td>\n",
       "      <td>163.507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>4.84%</td>\n",
       "      <td>1,322,821</td>\n",
       "      <td>600,689</td>\n",
       "      <td>152.494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>4.83%</td>\n",
       "      <td>1,317,728</td>\n",
       "      <td>704,889</td>\n",
       "      <td>152.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>4.81%</td>\n",
       "      <td>1,313,391</td>\n",
       "      <td>674,371</td>\n",
       "      <td>151.523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>3.97%</td>\n",
       "      <td>-</td>\n",
       "      <td>572,747</td>\n",
       "      <td>125.157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>3.85%</td>\n",
       "      <td>1,043,759</td>\n",
       "      <td>597,765</td>\n",
       "      <td>121.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>3.71%</td>\n",
       "      <td>994,154</td>\n",
       "      <td>568,086</td>\n",
       "      <td>116.862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>2.86%</td>\n",
       "      <td>774,869</td>\n",
       "      <td>432,960</td>\n",
       "      <td>90.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>2.77%</td>\n",
       "      <td>751,396</td>\n",
       "      <td>399,930</td>\n",
       "      <td>87.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>2.62%</td>\n",
       "      <td>673,107</td>\n",
       "      <td>433,769</td>\n",
       "      <td>82.442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1.76%</td>\n",
       "      <td>493,167</td>\n",
       "      <td>262,523</td>\n",
       "      <td>55.381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>1.73%</td>\n",
       "      <td>457,608</td>\n",
       "      <td>267,681</td>\n",
       "      <td>54.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>1.53%</td>\n",
       "      <td>393,722</td>\n",
       "      <td>243,348</td>\n",
       "      <td>48.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>1.16%</td>\n",
       "      <td>302,621</td>\n",
       "      <td>193,412</td>\n",
       "      <td>36.530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir-UT</td>\n",
       "      <td>0.85%</td>\n",
       "      <td>227,927</td>\n",
       "      <td>124,728</td>\n",
       "      <td>26.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>0.75%</td>\n",
       "      <td>195,405</td>\n",
       "      <td>126,433</td>\n",
       "      <td>23.659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>0.35%</td>\n",
       "      <td>-</td>\n",
       "      <td>55,548</td>\n",
       "      <td>11.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>0.27%</td>\n",
       "      <td>72,636</td>\n",
       "      <td>39,487</td>\n",
       "      <td>8.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>0.19%</td>\n",
       "      <td>-</td>\n",
       "      <td>30,287</td>\n",
       "      <td>6.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>0.19%</td>\n",
       "      <td>-</td>\n",
       "      <td>27,834</td>\n",
       "      <td>5.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>0.17%</td>\n",
       "      <td>42,697</td>\n",
       "      <td>24,267</td>\n",
       "      <td>5.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>42,756</td>\n",
       "      <td>20,728</td>\n",
       "      <td>5.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>-</td>\n",
       "      <td>20,515</td>\n",
       "      <td>4.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>-</td>\n",
       "      <td>19,801</td>\n",
       "      <td>4.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>-</td>\n",
       "      <td>18,363</td>\n",
       "      <td>4.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>-</td>\n",
       "      <td>18,494</td>\n",
       "      <td>3.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>0.04%</td>\n",
       "      <td>-</td>\n",
       "      <td>7,172</td>\n",
       "      <td>1.392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td></td>\n",
       "      <td>India</td>\n",
       "      <td>23,471,012</td>\n",
       "      <td>27,240,712</td>\n",
       "      <td>16,006,425</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State Share 22-21  GSDP 22-23  GSDP 21-22  \\\n",
       "0     1                Maharashtra      13.24%           -   2,027,971   \n",
       "1     2                 Tamil Nadu       8.82%   2,364,514   1,343,287   \n",
       "2     3              Uttar Pradesh       8.41%   2,257,575   1,204,660   \n",
       "3     4                  Karnataka       8.36%   2,241,368   1,229,713   \n",
       "4     5                    Gujarat       8.25%           -   1,372,204   \n",
       "5     6                West Bengal       5.81%   1,554,992     787,758   \n",
       "6     7                  Rajasthan       5.19%   1,413,620     738,922   \n",
       "7     8             Madhya Pradesh       4.84%   1,322,821     600,689   \n",
       "8     9             Andhra Pradesh       4.83%   1,317,728     704,889   \n",
       "9    10                  Telangana       4.81%   1,313,391     674,371   \n",
       "10   11                     Kerala       3.97%           -     572,747   \n",
       "11   12                      Delhi       3.85%   1,043,759     597,765   \n",
       "12   13                    Haryana       3.71%     994,154     568,086   \n",
       "13   14                     Odisha       2.86%     774,869     432,960   \n",
       "14   15                      Bihar       2.77%     751,396     399,930   \n",
       "15   16                     Punjab       2.62%     673,107     433,769   \n",
       "16   17                      Assam       1.76%     493,167     262,523   \n",
       "17   18               Chhattisgarh       1.73%     457,608     267,681   \n",
       "18   19                  Jharkhand       1.53%     393,722     243,348   \n",
       "19   20                Uttarakhand       1.16%     302,621     193,412   \n",
       "20   21         Jammu & Kashmir-UT       0.85%     227,927     124,728   \n",
       "21   22           Himachal Pradesh       0.75%     195,405     126,433   \n",
       "22   23                        Goa       0.35%           -      55,548   \n",
       "23   24                    Tripura       0.27%      72,636      39,487   \n",
       "24   25                 Chandigarh       0.19%           -      30,287   \n",
       "25   26                 Puducherry       0.19%           -      27,834   \n",
       "26   27                  Meghalaya       0.17%      42,697      24,267   \n",
       "27   28                     Sikkim       0.16%      42,756      20,728   \n",
       "28   29                    Manipur       0.16%           -      20,515   \n",
       "29   30          Arunachal Pradesh       0.15%           -      19,801   \n",
       "30   31                   Nagaland       0.14%           -      18,363   \n",
       "31   32                    Mizoram       0.12%           -      18,494   \n",
       "32   33  Andaman & Nicobar Islands       0.04%           -       7,172   \n",
       "33                           India  23,471,012  27,240,712  16,006,425   \n",
       "\n",
       "   GDP($ billion)  \n",
       "0         417.163  \n",
       "1         278.011  \n",
       "2         265.024  \n",
       "3         263.440  \n",
       "4         259.996  \n",
       "5         183.068  \n",
       "6         163.507  \n",
       "7         152.494  \n",
       "8         152.185  \n",
       "9         151.523  \n",
       "10        125.157  \n",
       "11        121.422  \n",
       "12        116.862  \n",
       "13         90.047  \n",
       "14         87.284  \n",
       "15         82.442  \n",
       "16         55.381  \n",
       "17         54.550  \n",
       "18         48.167  \n",
       "19         36.530  \n",
       "20         26.833  \n",
       "21         23.659  \n",
       "22         11.087  \n",
       "23          8.396  \n",
       "24          6.125  \n",
       "25          5.938  \n",
       "26          5.206  \n",
       "27          5.041  \n",
       "28          4.912  \n",
       "29          4.714  \n",
       "30          4.283  \n",
       "31          3.735  \n",
       "32          1.392  \n",
       "33                 "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3=pd.DataFrame({'Rank':rank,'State':state,'Share 22-21':share,'GSDP 22-23':gsdp_1,'GSDP 21-22':gsdp_2,'GDP($ billion)':gdp})\n",
    "df_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b97fd05",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "48b67574",
   "metadata": {},
   "outputs": [],
   "source": [
    "#automating chrome browser\n",
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://github.com/\")\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "abdca342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#automating path from open source tab to trending repositories\n",
    "os_tab=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button\")\n",
    "os_tab.click() \n",
    "sleep(2)\n",
    "trend_tab=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a\")\n",
    "trend_tab.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5a96096",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=[]\n",
    "title=[]\n",
    "\n",
    "#scraping urls and repository titles\n",
    "for url in driver.find_elements(By.XPATH,\"//h2[@class='h3 lh-condensed']/a\"):\n",
    "    urls.append(url.get_attribute('href'))\n",
    "    \n",
    "for t in driver.find_elements(By.XPATH,\"//h2[@class='h3 lh-condensed']/a\"):\n",
    "    title.append(t.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55306fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25\n"
     ]
    }
   ],
   "source": [
    "print(len(urls),len(title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9f7509a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "desp=[]\n",
    "contributor_count=[]\n",
    "lang=[]\n",
    "\n",
    "#iterating the urls\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    sleep(2)\n",
    "    \n",
    "    #scraping repository description\n",
    "    try:\n",
    "        desc_ = driver.find_elements(By.XPATH, \"//p[@class='f4 my-3']\")\n",
    "        if desc_:\n",
    "            for desc in desc_:\n",
    "                desp.append(desc.text)\n",
    "        else:\n",
    "            desp.append('-')\n",
    "    except Exception:\n",
    "        print('Error1')\n",
    "        \n",
    "    #scraping contributors count    \n",
    "    try:\n",
    "        elements = driver.find_elements(By.XPATH,\"//a[contains(text(),'Contributors')]/span\")\n",
    "        if elements:    \n",
    "            for contri_count in elements:\n",
    "                contributor_count.append(contri_count.text)\n",
    "        else:\n",
    "            contributor_count.append('-')\n",
    "    except Exception:\n",
    "        print('Error2')\n",
    "    \n",
    "    #scraping languages\n",
    "    try:\n",
    "        #creatings sep list to store various languages of a single repository\n",
    "        items=[]\n",
    "        for item in driver.find_elements(By.XPATH,\"//span[@class='color-fg-default text-bold mr-1']\"):\n",
    "            items.append(item.text)\n",
    "        lang.append(items)       \n",
    "    except Exception:\n",
    "        lang.append('-')\n",
    "\n",
    "driver.quit()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9ccea2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository Title</th>\n",
       "      <th>Repository Description</th>\n",
       "      <th>Contributors Count</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cloudflare / pingora</td>\n",
       "      <td>A library for building fast, reliable and evol...</td>\n",
       "      <td>29</td>\n",
       "      <td>[Rust]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lissy93 / web-check</td>\n",
       "      <td>üïµÔ∏è‚Äç‚ôÇÔ∏è All-in-one OSINT tool for analysing any ...</td>\n",
       "      <td>14</td>\n",
       "      <td>[TypeScript, JavaScript, HTML, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>polyfillpolyfill / polyfill-service</td>\n",
       "      <td>Automatic polyfill service.</td>\n",
       "      <td>168</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HumanAIGC / EMO</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cloudcommunity / Free-Certifications</td>\n",
       "      <td>A curated list of free courses &amp; certifications.</td>\n",
       "      <td>69</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>yuzu-emu / yuzu</td>\n",
       "      <td>Nintendo Switch emulator</td>\n",
       "      <td>298</td>\n",
       "      <td>[C++, Kotlin, CMake, GLSL, NASL, Python, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>microsoft / generative-ai-for-beginners</td>\n",
       "      <td>18 Lessons, Get Started Building with Generati...</td>\n",
       "      <td>50</td>\n",
       "      <td>[Jupyter Notebook, Python, TypeScript, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HumanAIGC / AnimateAnyone</td>\n",
       "      <td>Animate Anyone: Consistent and Controllable Im...</td>\n",
       "      <td>-</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kyegomez / BitNet</td>\n",
       "      <td>Implementation of \"BitNet: Scaling 1-bit Trans...</td>\n",
       "      <td>4</td>\n",
       "      <td>[Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dockur / windows</td>\n",
       "      <td>Windows in a Docker container.</td>\n",
       "      <td>4</td>\n",
       "      <td>[Shell, Dockerfile]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FuelLabs / fuel-core</td>\n",
       "      <td>Rust full node implementation of the Fuel v2 p...</td>\n",
       "      <td>48</td>\n",
       "      <td>[Rust, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dair-ai / ML-Papers-of-the-Week</td>\n",
       "      <td>üî•Highlighting the top ML papers every week.</td>\n",
       "      <td>7</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1c7 / chinese-independent-developer</td>\n",
       "      <td>üë©üèø‚Äçüíªüë®üèæ‚Äçüíªüë©üèº‚Äçüíªüë®üèΩ‚Äçüíªüë©üèª‚Äçüíª‰∏≠ÂõΩÁã¨Á´ãÂºÄÂèëËÄÖÈ°πÁõÆÂàóË°® -- ÂàÜ‰∫´Â§ßÂÆ∂ÈÉΩÂú®ÂÅö‰ªÄ‰πà</td>\n",
       "      <td>137</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>memorysafety / river</td>\n",
       "      <td>This repository is the future home of the Rive...</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Avaiga / taipy</td>\n",
       "      <td>Turns Data and AI algorithms into production-r...</td>\n",
       "      <td>31</td>\n",
       "      <td>[Python, TypeScript, CSS, JavaScript, Jupyter ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>aishwaryanr / awesome-generative-ai-guide</td>\n",
       "      <td>A one stop repository for generative AI resear...</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>wazuh / wazuh</td>\n",
       "      <td>Wazuh - The Open Source Security Platform. Uni...</td>\n",
       "      <td>288</td>\n",
       "      <td>[C, Python, C++, CMake, Shell, Makefile, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>myshell-ai / MeloTTS</td>\n",
       "      <td>High-quality multi-lingual text-to-speech libr...</td>\n",
       "      <td>6</td>\n",
       "      <td>[Python, Jupyter Notebook, Dockerfile]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pure-admin / vue-pure-admin</td>\n",
       "      <td>üî• ÂÖ®Èù¢ESM+Vue3+Vite+Element-Plus+TypeScriptÁºñÂÜôÁöÑ‰∏ÄÊ¨æ...</td>\n",
       "      <td>56</td>\n",
       "      <td>[Vue, TypeScript, SCSS, HTML, CSS, JavaScript]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>python-poetry / poetry</td>\n",
       "      <td>Python packaging and dependency management mad...</td>\n",
       "      <td>544</td>\n",
       "      <td>[Python, HTML]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>microsoft / unilm</td>\n",
       "      <td>Large-scale Self-supervised Pre-training Acros...</td>\n",
       "      <td>56</td>\n",
       "      <td>[Python, Jupyter Notebook, Shell, Cuda, C++, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>redis / ioredis</td>\n",
       "      <td>üöÄ A robust, performance-focused, and full-feat...</td>\n",
       "      <td>150</td>\n",
       "      <td>[TypeScript, JavaScript, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>FuelLabs / fuels-rs</td>\n",
       "      <td>Fuel Network Rust SDK</td>\n",
       "      <td>39</td>\n",
       "      <td>[Rust, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ossu / computer-science</td>\n",
       "      <td>üéì Path to a free self-taught education in Comp...</td>\n",
       "      <td>136</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>embedchain / embedchain</td>\n",
       "      <td>The Open Source RAG framework</td>\n",
       "      <td>83</td>\n",
       "      <td>[Python, Jupyter Notebook, TypeScript, Makefil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Repository Title  \\\n",
       "0                        cloudflare / pingora   \n",
       "1                         Lissy93 / web-check   \n",
       "2         polyfillpolyfill / polyfill-service   \n",
       "3                             HumanAIGC / EMO   \n",
       "4        cloudcommunity / Free-Certifications   \n",
       "5                             yuzu-emu / yuzu   \n",
       "6     microsoft / generative-ai-for-beginners   \n",
       "7                   HumanAIGC / AnimateAnyone   \n",
       "8                           kyegomez / BitNet   \n",
       "9                            dockur / windows   \n",
       "10                       FuelLabs / fuel-core   \n",
       "11            dair-ai / ML-Papers-of-the-Week   \n",
       "12        1c7 / chinese-independent-developer   \n",
       "13                       memorysafety / river   \n",
       "14                             Avaiga / taipy   \n",
       "15  aishwaryanr / awesome-generative-ai-guide   \n",
       "16                              wazuh / wazuh   \n",
       "17                       myshell-ai / MeloTTS   \n",
       "18                pure-admin / vue-pure-admin   \n",
       "19                     python-poetry / poetry   \n",
       "20                          microsoft / unilm   \n",
       "21                            redis / ioredis   \n",
       "22                        FuelLabs / fuels-rs   \n",
       "23                    ossu / computer-science   \n",
       "24                    embedchain / embedchain   \n",
       "\n",
       "                               Repository Description Contributors Count  \\\n",
       "0   A library for building fast, reliable and evol...                 29   \n",
       "1   üïµÔ∏è‚Äç‚ôÇÔ∏è All-in-one OSINT tool for analysing any ...                 14   \n",
       "2                         Automatic polyfill service.                168   \n",
       "3                                                   -                  -   \n",
       "4    A curated list of free courses & certifications.                 69   \n",
       "5                            Nintendo Switch emulator                298   \n",
       "6   18 Lessons, Get Started Building with Generati...                 50   \n",
       "7   Animate Anyone: Consistent and Controllable Im...                  -   \n",
       "8   Implementation of \"BitNet: Scaling 1-bit Trans...                  4   \n",
       "9                      Windows in a Docker container.                  4   \n",
       "10  Rust full node implementation of the Fuel v2 p...                 48   \n",
       "11        üî•Highlighting the top ML papers every week.                  7   \n",
       "12       üë©üèø‚Äçüíªüë®üèæ‚Äçüíªüë©üèº‚Äçüíªüë®üèΩ‚Äçüíªüë©üèª‚Äçüíª‰∏≠ÂõΩÁã¨Á´ãÂºÄÂèëËÄÖÈ°πÁõÆÂàóË°® -- ÂàÜ‰∫´Â§ßÂÆ∂ÈÉΩÂú®ÂÅö‰ªÄ‰πà                137   \n",
       "13  This repository is the future home of the Rive...                  2   \n",
       "14  Turns Data and AI algorithms into production-r...                 31   \n",
       "15  A one stop repository for generative AI resear...                  2   \n",
       "16  Wazuh - The Open Source Security Platform. Uni...                288   \n",
       "17  High-quality multi-lingual text-to-speech libr...                  6   \n",
       "18  üî• ÂÖ®Èù¢ESM+Vue3+Vite+Element-Plus+TypeScriptÁºñÂÜôÁöÑ‰∏ÄÊ¨æ...                 56   \n",
       "19  Python packaging and dependency management mad...                544   \n",
       "20  Large-scale Self-supervised Pre-training Acros...                 56   \n",
       "21  üöÄ A robust, performance-focused, and full-feat...                150   \n",
       "22                              Fuel Network Rust SDK                 39   \n",
       "23  üéì Path to a free self-taught education in Comp...                136   \n",
       "24                      The Open Source RAG framework                 83   \n",
       "\n",
       "                                             Language  \n",
       "0                                              [Rust]  \n",
       "1               [TypeScript, JavaScript, HTML, Other]  \n",
       "2                                                  []  \n",
       "3                                                  []  \n",
       "4                                                  []  \n",
       "5     [C++, Kotlin, CMake, GLSL, NASL, Python, Other]  \n",
       "6       [Jupyter Notebook, Python, TypeScript, Other]  \n",
       "7                                                  []  \n",
       "8                                            [Python]  \n",
       "9                                 [Shell, Dockerfile]  \n",
       "10                                      [Rust, Other]  \n",
       "11                                                 []  \n",
       "12                                                 []  \n",
       "13                                                 []  \n",
       "14  [Python, TypeScript, CSS, JavaScript, Jupyter ...  \n",
       "15                                                 []  \n",
       "16    [C, Python, C++, CMake, Shell, Makefile, Other]  \n",
       "17             [Python, Jupyter Notebook, Dockerfile]  \n",
       "18     [Vue, TypeScript, SCSS, HTML, CSS, JavaScript]  \n",
       "19                                     [Python, HTML]  \n",
       "20  [Python, Jupyter Notebook, Shell, Cuda, C++, C...  \n",
       "21                    [TypeScript, JavaScript, Other]  \n",
       "22                                      [Rust, Shell]  \n",
       "23                                                 []  \n",
       "24  [Python, Jupyter Notebook, TypeScript, Makefil...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_4=pd.DataFrame({'Repository Title':title,'Repository Description':desp,'Contributors Count':contributor_count,'Language':lang})\n",
    "df_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f5b8bc",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65ed673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#automating chrome browser\n",
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://www.billboard.com/\")\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ddcd5ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_tab=driver.find_element(By.XPATH,\"/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a\")\n",
    "chart_tab.click()\n",
    "sleep(2)\n",
    "hot_tab=driver.find_element(By.XPATH,\"/html/body/div[3]/main/div[2]/div[1]/div[1]/div/div/div[1]/div/div[2]/span/a\")\n",
    "hot_tab.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62bb9676",
   "metadata": {},
   "outputs": [],
   "source": [
    "song=[]\n",
    "artist=[]\n",
    "lw_rank=[]\n",
    "peak_rank=[]\n",
    "weeks=[]\n",
    "\n",
    "WebDriverWait(driver, 4).until(EC.presence_of_element_located((By.XPATH,\"/html/body/div[3]/main/div[2]/div[3]/div/div/div/div[2]/div[2]/ul/li[4]/ul/li[1]/h3\")))\n",
    "\n",
    "#scraping Song Name\n",
    "try:\n",
    "    for name in driver.find_elements(By.XPATH,\"//div[@class='u-max-width-970 lrv-u-margin-lr-auto']/div[2]/div/ul/li[4]/ul/li/h3\"):\n",
    "        song.append(name.text)\n",
    "except Exception:\n",
    "    song.append('-')\n",
    "    \n",
    "        \n",
    "#scraping artist name\n",
    "\n",
    "try:\n",
    "    for art in driver.find_elements(By.XPATH,\"//div[@class='u-max-width-970 lrv-u-margin-lr-auto']/div[2]/div/ul/li[4]/ul/li[1]/span[1]\"):\n",
    "        artist.append(art.text.replace('¬•$:',''))\n",
    "except Exception:\n",
    "    artist.append('-')\n",
    "    \n",
    "#scraping last week position\n",
    "\n",
    "try:\n",
    "    for lw in driver.find_elements(By.XPATH,\"//div[@class='u-max-width-970 lrv-u-margin-lr-auto']/div[2]/div/ul/li[4]/ul/li[4]/span\"):\n",
    "        lw_rank.append(lw.text)\n",
    "except Exception:\n",
    "    lw_rank.append('-')\n",
    "    \n",
    "#scraping peak position\n",
    "\n",
    "try:\n",
    "    for peak in driver.find_elements(By.XPATH,\"//div[@class='u-max-width-970 lrv-u-margin-lr-auto']/div[2]/div/ul/li[4]/ul/li[5]/span\"):\n",
    "        peak_rank.append(peak.text)\n",
    "except Exception:\n",
    "    peak_rank.append('-')\n",
    "    \n",
    "#scraping weeks on board\n",
    "\n",
    "try:\n",
    "    for week in driver.find_elements(By.XPATH,\"//div[@class='u-max-width-970 lrv-u-margin-lr-auto']/div[2]/div/ul/li[4]/ul/li[6]/span\"):\n",
    "        weeks.append(week.text)\n",
    "except Exception:\n",
    "    weeks.append('-')\n",
    "    \n",
    "driver.quit()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0246f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Last Week Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks On Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Texas Hold 'Em</td>\n",
       "      <td>Beyonce</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lovin On Me</td>\n",
       "      <td>Jack Harlow</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lose Control</td>\n",
       "      <td>Teddy Swims</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Carnival</td>\n",
       "      <td>Kanye West &amp; Ty Dolla $ign Featuring Rich The...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beautiful Things</td>\n",
       "      <td>Benson Boone</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Talking</td>\n",
       "      <td>Kanye West &amp; Ty Dolla $ign Featuring North West</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Monaco</td>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td>97</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Where It Ends</td>\n",
       "      <td>Bailey Zimmerman</td>\n",
       "      <td>-</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Wondering Why</td>\n",
       "      <td>The Red Clay Strays</td>\n",
       "      <td>-</td>\n",
       "      <td>71</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Northern Attitude</td>\n",
       "      <td>Noah Kahan With Hozier</td>\n",
       "      <td>75</td>\n",
       "      <td>37</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Song Name                                        Artist Name  \\\n",
       "0      Texas Hold 'Em                                            Beyonce   \n",
       "1         Lovin On Me                                        Jack Harlow   \n",
       "2        Lose Control                                        Teddy Swims   \n",
       "3            Carnival   Kanye West & Ty Dolla $ign Featuring Rich The...   \n",
       "4    Beautiful Things                                       Benson Boone   \n",
       "..                ...                                                ...   \n",
       "95            Talking    Kanye West & Ty Dolla $ign Featuring North West   \n",
       "96             Monaco                                          Bad Bunny   \n",
       "97      Where It Ends                                   Bailey Zimmerman   \n",
       "98      Wondering Why                                The Red Clay Strays   \n",
       "99  Northern Attitude                             Noah Kahan With Hozier   \n",
       "\n",
       "   Last Week Rank Peak Rank Weeks On Board  \n",
       "0               2         1              2  \n",
       "1               1         1             15  \n",
       "2               5         2             28  \n",
       "3               3         3              2  \n",
       "4               4         3              5  \n",
       "..            ...       ...            ...  \n",
       "95             30        30              2  \n",
       "96             97         5             19  \n",
       "97              -        32              8  \n",
       "98              -        71              8  \n",
       "99             75        37             12  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_5=pd.DataFrame({'Song Name':song,'Artist Name':artist,'Last Week Rank':lw_rank,'Peak Rank':peak_rank,'Weeks On Board':weeks})\n",
    "df_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0663fe9c",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8352a7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#automating chrome browser\n",
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2cfc23b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "book=[]\n",
    "author=[]\n",
    "volume=[]\n",
    "publisher=[]\n",
    "genre=[]\n",
    "\n",
    "WebDriverWait(driver, 4).until(EC.presence_of_element_located((By.XPATH,\"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tfoot\")))\n",
    "\n",
    "#scraping book Name\n",
    "try:\n",
    "    for name in driver.find_elements(By.XPATH,\"//div[@class='embed block']/table/tbody/tr/td[2]\"):\n",
    "        book.append(name.text)\n",
    "except Exception:\n",
    "    book.append('-')\n",
    "    \n",
    "        \n",
    "#scraping author name\n",
    "\n",
    "try:\n",
    "    for art in driver.find_elements(By.XPATH,\"//div[@class='embed block']/table/tbody/tr/td[3]\"):\n",
    "        author.append(art.text)\n",
    "except Exception:\n",
    "    author.append('-')\n",
    "    \n",
    "#scraping volumes sold\n",
    "\n",
    "try:\n",
    "    for vol in driver.find_elements(By.XPATH,\"//div[@class='embed block']/table/tbody/tr/td[4]\"):\n",
    "        volume.append(vol.text)\n",
    "except Exception:\n",
    "    volume.append('-')\n",
    "    \n",
    "#scraping publisher\n",
    "\n",
    "try:\n",
    "    for pub in driver.find_elements(By.XPATH,\"//div[@class='embed block']/table/tbody/tr/td[5]\"):\n",
    "        publisher.append(pub.text)\n",
    "except Exception:\n",
    "    publisher.append('-')\n",
    "    \n",
    "#scraping genre\n",
    "\n",
    "try:\n",
    "    for gen in driver.find_elements(By.XPATH,\"//div[@class='embed block']/table/tbody/tr/td[6]\"):\n",
    "        genre.append(gen.text)\n",
    "except Exception:\n",
    "    genre.append('-')\n",
    "    \n",
    "driver.quit()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3f09786b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volume Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume Sold        Publisher                        Genre  \n",
       "0    5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1    4,475,152       Bloomsbury           Children's Fiction  \n",
       "2    4,200,654       Bloomsbury           Children's Fiction  \n",
       "3    4,179,479       Bloomsbury           Children's Fiction  \n",
       "4    3,758,936     Random House              Romance & Sagas  \n",
       "..         ...              ...                          ...  \n",
       "95     807,311     Random House   General & Literary Fiction  \n",
       "96     794,201          Penguin        Food & Drink: General  \n",
       "97     792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98     791,507            Orion           Biography: General  \n",
       "99     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_6=pd.DataFrame({'Book Name':book,'Author Name':author,'Volume Sold':volume,'Publisher':publisher,'Genre':genre})\n",
    "df_6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ab2aaf",
   "metadata": {},
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c4c0da1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#automating chrome browser\n",
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://www.imdb.com/list/ls512407256/\")\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ab0d6b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "series=[]\n",
    "span=[]\n",
    "gen=[]\n",
    "runtime=[]\n",
    "ratings=[]\n",
    "votes=[]\n",
    "\n",
    "#scraping series Name\n",
    "try:\n",
    "    for name in driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/a\"):\n",
    "        series.append(name.text)\n",
    "except Exception:\n",
    "    series.append('-')\n",
    "    \n",
    "        \n",
    "#scraping year span\n",
    "\n",
    "try:\n",
    "    for t in driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/span[2]\"):\n",
    "        span.append(t.text)\n",
    "except Exception:\n",
    "    span.append('-')\n",
    "    \n",
    "#scraping runtime\n",
    "\n",
    "try:\n",
    "    for run in driver.find_elements(By.XPATH,\"//span[@class='runtime']\"):\n",
    "        runtime.append(run.text)\n",
    "except Exception:\n",
    "    runtime.append('-')\n",
    "    \n",
    "#scraping ratings\n",
    "\n",
    "try:\n",
    "    for rate in driver.find_elements(By.XPATH,\"//div[@class='ipl-rating-star small']/span[@class='ipl-rating-star__rating']\"):\n",
    "        ratings.append(rate.text)\n",
    "except Exception:\n",
    "    ratings.append('-')\n",
    "    \n",
    "#scraping genre\n",
    "\n",
    "try:\n",
    "    for genre in driver.find_elements(By.XPATH,\"//span[@class='genre']\"):\n",
    "        gen.append(genre.text)\n",
    "except Exception:\n",
    "    gen.append('-')\n",
    "    \n",
    "#scraping votes\n",
    "\n",
    "try:\n",
    "    for vote in driver.find_elements(By.XPATH,\"//span[@name='nv']\"):\n",
    "        votes.append(vote.text)\n",
    "except Exception:\n",
    "    votes.append('-')    \n",
    "    \n",
    "driver.quit()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ade3e9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011‚Äì2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>55 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,262,743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016‚Äì2025)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,320,608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010‚Äì2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,072,366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017‚Äì2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>313,495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014‚Äì2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>273,435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>True Detective</td>\n",
       "      <td>(2014‚Äì )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>55 min</td>\n",
       "      <td>8.9</td>\n",
       "      <td>645,816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Teen Wolf</td>\n",
       "      <td>(2011‚Äì2017)</td>\n",
       "      <td>Action, Drama, Fantasy</td>\n",
       "      <td>41 min</td>\n",
       "      <td>7.7</td>\n",
       "      <td>162,075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>The OA</td>\n",
       "      <td>(2016‚Äì2019)</td>\n",
       "      <td>Drama, Fantasy, Mystery</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>114,891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>The Simpsons</td>\n",
       "      <td>(1989‚Äì )</td>\n",
       "      <td>Animation, Comedy</td>\n",
       "      <td>22 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>433,124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Desperate Housewives</td>\n",
       "      <td>(2004‚Äì2012)</td>\n",
       "      <td>Comedy, Drama, Mystery</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>138,702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Series Name    Year Span                    Genres Run Time  \\\n",
       "0        Game of Thrones  (2011‚Äì2019)  Action, Adventure, Drama   55 min   \n",
       "1        Stranger Things  (2016‚Äì2025)    Drama, Fantasy, Horror   51 min   \n",
       "2       The Walking Dead  (2010‚Äì2022)   Drama, Horror, Thriller   44 min   \n",
       "3         13 Reasons Why  (2017‚Äì2020)  Drama, Mystery, Thriller   60 min   \n",
       "4                The 100  (2014‚Äì2020)    Drama, Mystery, Sci-Fi   43 min   \n",
       "..                   ...          ...                       ...      ...   \n",
       "95        True Detective     (2014‚Äì )     Crime, Drama, Mystery   55 min   \n",
       "96             Teen Wolf  (2011‚Äì2017)    Action, Drama, Fantasy   41 min   \n",
       "97                The OA  (2016‚Äì2019)   Drama, Fantasy, Mystery   60 min   \n",
       "98          The Simpsons     (1989‚Äì )         Animation, Comedy   22 min   \n",
       "99  Desperate Housewives  (2004‚Äì2012)    Comedy, Drama, Mystery   45 min   \n",
       "\n",
       "   Ratings      Votes  \n",
       "0      9.2  2,262,743  \n",
       "1      8.7  1,320,608  \n",
       "2      8.1  1,072,366  \n",
       "3      7.5    313,495  \n",
       "4      7.6    273,435  \n",
       "..     ...        ...  \n",
       "95     8.9    645,816  \n",
       "96     7.7    162,075  \n",
       "97     7.8    114,891  \n",
       "98     8.7    433,124  \n",
       "99     7.6    138,702  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_7=pd.DataFrame({'Series Name':series,'Year Span':span,'Genres':gen,'Run Time':runtime,'Ratings':ratings,'Votes':votes})\n",
    "df_7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8df97bc",
   "metadata": {},
   "source": [
    "## Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c1bfc249",
   "metadata": {},
   "outputs": [],
   "source": [
    "#automating chrome browser\n",
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://archive.ics.uci.edu/\")\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8a7251fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#automating path\n",
    "dataset_tab=driver.find_element(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]\")\n",
    "dataset.click()\n",
    "sleep(2)\n",
    "expand_tab=driver.find_element(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div[2]/div[1]/div/label[2]/div[2]/span[2]\")\n",
    "expand_tab.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d484a399",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=[]\n",
    "dt=[]\n",
    "task=[]\n",
    "ft_type=[]\n",
    "instance=[]\n",
    "ft=[]\n",
    "year=[]\n",
    "\n",
    "\n",
    "#scraping dataset Name\n",
    "try:\n",
    "    for name in driver.find_elements(By.XPATH,\"//a[@class='link-hover link text-xl font-semibold']\"):\n",
    "        ds.append(name.text)\n",
    "except Exception:\n",
    "    ds.append('-')\n",
    "\n",
    "\n",
    "#scraping datatype\n",
    "\n",
    "try:\n",
    "    for t in driver.find_elements(By.XPATH,\"//div[@class='col-span-1 flex w-full flex-col gap-4 p-4']/div[2]/div/div/div[2]/div/div[2]/span\"):\n",
    "        dt.append(t.text)\n",
    "except Exception:\n",
    "    dt.append('-')\n",
    "\n",
    "#scraping task\n",
    "\n",
    "try:\n",
    "    for k in driver.find_elements(By.XPATH,\"//div[@class='col-span-1 flex w-full flex-col gap-4 p-4']/div[2]/div/div/div[2]/div/div[1]/span\"):\n",
    "        task.append(k.text)\n",
    "except Exception:\n",
    "    task.append('-')\n",
    "\n",
    "#scraping feature type\n",
    "\n",
    "try:\n",
    "    for feat in driver.find_elements(By.XPATH,\"//div[@class='flex flex-col gap-1']/div/div[2]/div/table/tbody/tr/td[2]\"):\n",
    "        ft_type.append(feat.text)\n",
    "except Exception:\n",
    "    ft_type.append('-')\n",
    "\n",
    "#scraping instances\n",
    "\n",
    "try:\n",
    "    num = driver.find_elements(By.XPATH,\"//div[@class='col-span-1 flex w-full flex-col gap-4 p-4']/div[2]/div/div/div[2]/div/div[3]/span\")\n",
    "    for n in num: \n",
    "        instance.append(n.text)\n",
    "except Exception:\n",
    "    instance.append('-')\n",
    "\n",
    "#scraping features\n",
    "\n",
    "try:\n",
    "    feature= driver.find_elements(By.XPATH,\"//div[@class='col-span-1 flex w-full flex-col gap-4 p-4']/div[2]/div/div/div[2]/div/div[4]/span\")\n",
    "    for f in feature:   \n",
    "        ft.append(f.text)\n",
    "except Exception:\n",
    "    ft.append('-')\n",
    "\n",
    "#scraping year\n",
    "\n",
    "try:\n",
    "    for y in driver.find_elements(By.XPATH,\"//div[@class='flex flex-col gap-1']/div/div[2]/div/table/tbody/tr/td[3]\"):\n",
    "        year_=y.text\n",
    "        #using regex findall(), to scrap year from date \n",
    "        match=re.findall(r'\\b\\d{4}\\b',year_)\n",
    "        year.append(match)\n",
    "except Exception:\n",
    "    year.append('-')    \n",
    "\n",
    "\n",
    "driver.quit()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "da431cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>No of Instances</th>\n",
       "      <th>No of Attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150 Instances</td>\n",
       "      <td>4 Features</td>\n",
       "      <td>[1988]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13.61K Instances</td>\n",
       "      <td>16 Features</td>\n",
       "      <td>[2020]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "      <td>[1988]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>3.81K Instances</td>\n",
       "      <td>7 Features</td>\n",
       "      <td>[2019]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48.84K Instances</td>\n",
       "      <td>14 Features</td>\n",
       "      <td>[1996]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Raisin</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real, Integer</td>\n",
       "      <td>900 Instances</td>\n",
       "      <td>8 Features</td>\n",
       "      <td>[2023]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>569 Instances</td>\n",
       "      <td>30 Features</td>\n",
       "      <td>[1995]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>178 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "      <td>[1991]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wine Quality</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4.9K Instances</td>\n",
       "      <td>12 Features</td>\n",
       "      <td>[2009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>1 Instances</td>\n",
       "      <td>20 Features</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Car Evaluation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>1.73K Instances</td>\n",
       "      <td>6 Features</td>\n",
       "      <td>[1997]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bank Marketing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>45.21K Instances</td>\n",
       "      <td>17 Features</td>\n",
       "      <td>[2012]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mushroom</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>8.12K Instances</td>\n",
       "      <td>22 Features</td>\n",
       "      <td>[1987]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4.18K Instances</td>\n",
       "      <td>8 Features</td>\n",
       "      <td>[1995]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Student Performance</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Integer</td>\n",
       "      <td>649 Instances</td>\n",
       "      <td>33 Features</td>\n",
       "      <td>[2014]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Census Income</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48.84K Instances</td>\n",
       "      <td>14 Features</td>\n",
       "      <td>[1996]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Online Retail</td>\n",
       "      <td>Multivariate, Sequential, Time-Series</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>541.91K Instances</td>\n",
       "      <td>8 Features</td>\n",
       "      <td>[2015]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Automobile</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>205 Instances</td>\n",
       "      <td>25 Features</td>\n",
       "      <td>[1987]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Statlog (German Credit Data)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>1K Instances</td>\n",
       "      <td>20 Features</td>\n",
       "      <td>[1994]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>286 Instances</td>\n",
       "      <td>9 Features</td>\n",
       "      <td>[1988]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Auto MPG</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real, Categorical, Integer</td>\n",
       "      <td>398 Instances</td>\n",
       "      <td>7 Features</td>\n",
       "      <td>[1993]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Breast Cancer Wisconsin (Original)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer</td>\n",
       "      <td>699 Instances</td>\n",
       "      <td>9 Features</td>\n",
       "      <td>[1992]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Spambase</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>4.6K Instances</td>\n",
       "      <td>57 Features</td>\n",
       "      <td>[1999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Predict Students' Dropout and Academic Success</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real, Categorical, Integer</td>\n",
       "      <td>4.42K Instances</td>\n",
       "      <td>36 Features</td>\n",
       "      <td>[2021]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Glass Identification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>214 Instances</td>\n",
       "      <td>9 Features</td>\n",
       "      <td>[1987]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Dataset Name  \\\n",
       "0                                             Iris   \n",
       "1                                 Dry Bean Dataset   \n",
       "2                                    Heart Disease   \n",
       "3                       Rice (Cammeo and Osmancik)   \n",
       "4                                            Adult   \n",
       "5                                           Raisin   \n",
       "6             Breast Cancer Wisconsin (Diagnostic)   \n",
       "7                                             Wine   \n",
       "8                                     Wine Quality   \n",
       "9                                         Diabetes   \n",
       "10                                  Car Evaluation   \n",
       "11                                  Bank Marketing   \n",
       "12                                        Mushroom   \n",
       "13                                         Abalone   \n",
       "14                             Student Performance   \n",
       "15                                   Census Income   \n",
       "16                                   Online Retail   \n",
       "17                                      Automobile   \n",
       "18                    Statlog (German Credit Data)   \n",
       "19                                   Breast Cancer   \n",
       "20                                        Auto MPG   \n",
       "21              Breast Cancer Wisconsin (Original)   \n",
       "22                                        Spambase   \n",
       "23  Predict Students' Dropout and Academic Success   \n",
       "24                            Glass Identification   \n",
       "\n",
       "                                Data Type                        Task  \\\n",
       "0                                 Tabular              Classification   \n",
       "1                            Multivariate              Classification   \n",
       "2                            Multivariate              Classification   \n",
       "3                            Multivariate              Classification   \n",
       "4                            Multivariate              Classification   \n",
       "5                            Multivariate              Classification   \n",
       "6                            Multivariate              Classification   \n",
       "7                                 Tabular              Classification   \n",
       "8                            Multivariate  Classification, Regression   \n",
       "9               Multivariate, Time-Series              Classification   \n",
       "10                           Multivariate              Classification   \n",
       "11                           Multivariate              Classification   \n",
       "12                           Multivariate              Classification   \n",
       "13                                Tabular  Classification, Regression   \n",
       "14                           Multivariate  Classification, Regression   \n",
       "15                           Multivariate              Classification   \n",
       "16  Multivariate, Sequential, Time-Series  Classification, Clustering   \n",
       "17                           Multivariate                  Regression   \n",
       "18                           Multivariate              Classification   \n",
       "19                           Multivariate              Classification   \n",
       "20                           Multivariate                  Regression   \n",
       "21                           Multivariate              Classification   \n",
       "22                           Multivariate              Classification   \n",
       "23                                Tabular              Classification   \n",
       "24                           Multivariate              Classification   \n",
       "\n",
       "                Attribute Type    No of Instances No of Attribute    Year  \n",
       "0                         Real      150 Instances      4 Features  [1988]  \n",
       "1                Integer, Real   13.61K Instances     16 Features  [2020]  \n",
       "2   Categorical, Integer, Real      303 Instances     13 Features  [1988]  \n",
       "3                         Real    3.81K Instances      7 Features  [2019]  \n",
       "4         Categorical, Integer   48.84K Instances     14 Features  [1996]  \n",
       "5                Real, Integer      900 Instances      8 Features  [2023]  \n",
       "6                         Real      569 Instances     30 Features  [1995]  \n",
       "7                Integer, Real      178 Instances     13 Features  [1991]  \n",
       "8                         Real     4.9K Instances     12 Features  [2009]  \n",
       "9         Categorical, Integer        1 Instances     20 Features      []  \n",
       "10                 Categorical    1.73K Instances      6 Features  [1997]  \n",
       "11        Categorical, Integer   45.21K Instances     17 Features  [2012]  \n",
       "12                 Categorical    8.12K Instances     22 Features  [1987]  \n",
       "13  Categorical, Integer, Real    4.18K Instances      8 Features  [1995]  \n",
       "14                     Integer      649 Instances     33 Features  [2014]  \n",
       "15        Categorical, Integer   48.84K Instances     14 Features  [1996]  \n",
       "16               Integer, Real  541.91K Instances      8 Features  [2015]  \n",
       "17  Categorical, Integer, Real      205 Instances     25 Features  [1987]  \n",
       "18        Categorical, Integer       1K Instances     20 Features  [1994]  \n",
       "19                 Categorical      286 Instances      9 Features  [1988]  \n",
       "20  Real, Categorical, Integer      398 Instances      7 Features  [1993]  \n",
       "21                     Integer      699 Instances      9 Features  [1992]  \n",
       "22               Integer, Real     4.6K Instances     57 Features  [1999]  \n",
       "23  Real, Categorical, Integer    4.42K Instances     36 Features  [2021]  \n",
       "24                        Real      214 Instances      9 Features  [1987]  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_8=pd.DataFrame({'Dataset Name':ds,'Data Type':dt,'Task':task,'Attribute Type':ft_type,'No of Instances':instance,'No of Attribute':ft,'Year':year})\n",
    "df_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3e0c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
